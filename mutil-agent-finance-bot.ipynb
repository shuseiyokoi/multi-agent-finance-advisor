{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langgraph requests pandas matplotlib yfinance python-dateutil\n",
    "# !pip install feedparser beautifulsoup4 lxml html5lib     # optional RSS fallback\n",
    "# !pip install langchain-mcp-adapters mcp anyio            # optional MCP browsing\n",
    "# !pip install openai                                      # optional LLM intent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finance_multiagent_no_events_fixed_order.py\n",
    "from __future__ import annotations\n",
    "\n",
    "import os, math, time, re, hashlib, json\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Any, Optional\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "# ---------- Plotting (headless) ----------\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------- Data/HTTP ----------\n",
    "import requests\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from dateutil import parser as dateparser\n",
    "\n",
    "# ---------- LangGraph ----------\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# ---------- Optional modules ----------\n",
    "# RSS fallback (no MCP)\n",
    "try:\n",
    "    import feedparser\n",
    "    from bs4 import BeautifulSoup\n",
    "    HAVE_RSS = True\n",
    "except Exception:\n",
    "    HAVE_RSS = False\n",
    "\n",
    "# MCP (browsing)\n",
    "HAVE_MCP = False\n",
    "try:\n",
    "    import anyio\n",
    "    from langchain_mcp_adapters.client import MCPClient\n",
    "    HAVE_MCP = True\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# LLM (OpenAI or Azure OpenAI)\n",
    "HAVE_OPENAI = False\n",
    "try:\n",
    "    from openai import OpenAI\n",
    "    HAVE_OPENAI = True\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "USER_AGENT = {\"User-Agent\": \"Mozilla/5.0 (compatible; FinanceAgent/1.0)\"}\n",
    "\n",
    "# Enable MCP servers if you have them; leave {} to auto-fallback to RSS\n",
    "MCP_SERVERS: Dict[str, Dict[str, Any]] = {\n",
    "    # \"search\":  {\"command\": \"npx\", \"args\": [\"valueserp-googlesearch-mcp@latest\"]},\n",
    "    # \"browser\": {\"command\": \"npx\", \"args\": [\"@djyde/mcp-browser@latest\"]},\n",
    "}\n",
    "\n",
    "OPENAI_MODEL = os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\")\n",
    "OPENAI_BASE_URL = os.getenv(\"OPENAI_BASE_URL\")  # optional for Azure/proxy\n",
    "\n",
    "US_EXCHANGES = {\"NMS\",\"NAS\",\"NASDAQ\",\"NYQ\",\"NYSE\",\"NYE\",\"NCM\",\"NGM\",\"ASE\",\"PCX\",\"BATS\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class State:\n",
    "    question: str\n",
    "    tickers: List[str] = field(default_factory=list)\n",
    "    companies: List[str] = field(default_factory=list)\n",
    "\n",
    "    start: Optional[datetime] = None\n",
    "    end: Optional[datetime] = None\n",
    "    interval: str = \"1d\"\n",
    "\n",
    "    prices: Dict[str, pd.DataFrame] = field(default_factory=dict)\n",
    "    quotes: Dict[str, Dict[str, Any]] = field(default_factory=dict)\n",
    "    analysis: Dict[str, Any] = field(default_factory=dict)\n",
    "    charts: Dict[str, str] = field(default_factory=dict)\n",
    "    research: Dict[str, List[Dict[str, Any]]] = field(default_factory=dict)\n",
    "    report: str = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers: dates/intervals\n",
    "def _default_dates(start: Optional[datetime], end: Optional[datetime]):\n",
    "    end = end or datetime.now(timezone.utc)\n",
    "    start = start or (end - timedelta(days=182))  # ~6 months\n",
    "    return start, end\n",
    "\n",
    "def _pick_interval(start: datetime, end: datetime) -> str:\n",
    "    days = (end - start).days\n",
    "    if days <= 7: return \"15m\"\n",
    "    if days <= 60: return \"1h\"\n",
    "    if days <= 365: return \"1d\"\n",
    "    return \"1wk\"\n",
    "\n",
    "def _to_unix(dt: datetime) -> int:\n",
    "    return int(dt.timestamp())\n",
    "\n",
    "def _clean_text(x: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", (x or \"\")).strip()\n",
    "\n",
    "def _parse_date_or_none(s: Optional[str]) -> Optional[datetime]:\n",
    "    if not s: return None\n",
    "    try:\n",
    "        return dateparser.parse(s)\n",
    "    except Exception:\n",
    "        return None\n",
    "    \n",
    "def _to_state(x) -> State:\n",
    "    \"\"\"Coerce a dict result from LangGraph into the State dataclass.\"\"\"\n",
    "    if isinstance(x, State):\n",
    "        return x\n",
    "    allowed = set(State.__annotations__.keys())\n",
    "    return State(**{k: v for k, v in x.items() if k in allowed})\n",
    "\n",
    "def _print_result(x):\n",
    "    s = _to_state(x)\n",
    "    print(s.report)\n",
    "    print(s.charts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM intent extraction\n",
    "def _heuristic_parse(question: str) -> Dict[str, Any]:\n",
    "    out: Dict[str, Any] = {\"companies\": [], \"tickers\": [], \"date_from\": None, \"date_to\": None}\n",
    "    out[\"tickers\"] = re.findall(r\"\\b[A-Z]{1,5}\\b\", question)  # quick ALLCAPS capture\n",
    "    m = re.search(r\"from ([\\w\\-\\s:\\/]+) to ([\\w\\-\\s:\\/]+)\", question, re.I)\n",
    "    if m:\n",
    "        out[\"date_from\"], out[\"date_to\"] = m.group(1), m.group(2)\n",
    "    # naive company capture (capitalized phrases)\n",
    "    out[\"companies\"] = list({c for c in re.findall(r\"\\b([A-Z][a-zA-Z]+(?: [A-Z][a-zA-Z]+)*)\\b\", question) if len(c) > 2})\n",
    "    return out\n",
    "\n",
    "def _llm_extract(question: str) -> Dict[str, Any]:\n",
    "    if not HAVE_OPENAI or not os.getenv(\"OPENAI_API_KEY\"):\n",
    "        return _heuristic_parse(question)\n",
    "    try:\n",
    "        client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"), base_url=OPENAI_BASE_URL)\n",
    "        sys = (\"Extract finance intent. Return ONLY JSON: \"\n",
    "               \"{companies:[], tickers:[], date_from:null|string, date_to:null|string}.\")\n",
    "        resp = client.chat.completions.create(\n",
    "            model=OPENAI_MODEL,\n",
    "            messages=[{\"role\":\"system\",\"content\":sys},\n",
    "                      {\"role\":\"user\",\"content\":f\"Question: {question}\\nReturn JSON only.\"}],\n",
    "            temperature=0,\n",
    "            response_format={\"type\":\"json_object\"}\n",
    "        )\n",
    "        data = json.loads(resp.choices[0].message.content)\n",
    "        data.setdefault(\"companies\", []); data.setdefault(\"tickers\", [])\n",
    "        data.setdefault(\"date_from\", None); data.setdefault(\"date_to\", None)\n",
    "        return data\n",
    "    except Exception:\n",
    "        return _heuristic_parse(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yahoo Finance: Symbol Search (web lookup), Chart v8 + fallback\n",
    "def yahoo_symbol_search(query: str, region: str = \"US\", prefer_equity: bool = True) -> Optional[str]:\n",
    "    \"\"\"Resolve company name -> symbol using Yahoo's public search JSON (web lookup).\"\"\"\n",
    "    url = \"https://query2.finance.yahoo.com/v1/finance/search\"\n",
    "    params = {\n",
    "        \"q\": query, \"quotesCount\": 10, \"newsCount\": 0, \"listsCount\": 0,\n",
    "        \"enableFuzzyQuery\": \"true\", \"lang\": \"en-US\", \"region\": region\n",
    "    }\n",
    "    try:\n",
    "        r = requests.get(url, params=params, timeout=10, headers=USER_AGENT)\n",
    "        if r.status_code != 200:\n",
    "            return None\n",
    "        data = r.json()\n",
    "        quotes = data.get(\"quotes\", []) or []\n",
    "        if not quotes:\n",
    "            return None\n",
    "\n",
    "        def score(q):\n",
    "            s = 0\n",
    "            qt = (q.get(\"quoteType\") or q.get(\"typeDisp\") or \"\").upper()\n",
    "            exch = (q.get(\"exchange\") or q.get(\"exchDisp\") or \"\").upper()\n",
    "            if prefer_equity and (\"EQUITY\" in qt or qt in {\"S\",\"STOCK\"}): s += 3\n",
    "            if exch in US_EXCHANGES: s += 2\n",
    "            if q.get(\"isYahooFinance\"): s += 1\n",
    "            return (s, q.get(\"score\", 0))\n",
    "        best = sorted(quotes, key=score, reverse=True)[0]\n",
    "        return best.get(\"symbol\")\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def _get_chart_json(symbol: str, start: datetime, end: datetime, interval: str, max_retries=3) -> Dict:\n",
    "    base = f\"https://query2.finance.yahoo.com/v8/finance/chart/{symbol}\"\n",
    "    params = {\"period1\": _to_unix(start), \"period2\": _to_unix(end), \"interval\": interval}\n",
    "    backoff = 1.0\n",
    "    last_status = None\n",
    "    for _ in range(max_retries):\n",
    "        r = requests.get(base, params=params, timeout=15, headers=USER_AGENT)\n",
    "        last_status = r.status_code\n",
    "        if last_status == 200:\n",
    "            return r.json()\n",
    "        time.sleep(backoff); backoff *= 2\n",
    "    raise RuntimeError(f\"Yahoo chart v8 failed for {symbol}: HTTP {last_status}\")\n",
    "\n",
    "def _chart_to_dataframe(payload: Dict) -> pd.DataFrame:\n",
    "    res = payload[\"chart\"][\"result\"][0]\n",
    "    ts = res.get(\"timestamp\") or []\n",
    "    if not ts:\n",
    "        raise ValueError(\"No timestamps returned by Yahoo chart endpoint.\")\n",
    "    ind = pd.to_datetime(pd.Series(ts), unit=\"s\", utc=True)\n",
    "    q = res[\"indicators\"][\"quote\"][0]\n",
    "    df = pd.DataFrame({\n",
    "        \"open\": q[\"open\"], \"high\": q[\"high\"],\n",
    "        \"low\": q[\"low\"], \"close\": q[\"close\"], \"volume\": q[\"volume\"]\n",
    "    }, index=ind).sort_index()\n",
    "    return df\n",
    "\n",
    "def _yfinance_fallback(symbol: str, start: datetime, end: datetime, interval: str) -> pd.DataFrame:\n",
    "    iv_map = {\"15m\": \"15m\", \"1h\": \"60m\", \"1d\": \"1d\", \"1wk\": \"1wk\"}\n",
    "    yf_iv = iv_map.get(interval, \"1d\")\n",
    "    df = yf.download(symbol, start=start, end=end, interval=yf_iv, progress=False)\n",
    "    if df.empty:\n",
    "        raise RuntimeError(f\"yfinance returned empty frame for {symbol}\")\n",
    "    df.index = pd.to_datetime(df.index, utc=True)\n",
    "    df = df.rename(columns=str.lower)\n",
    "    return df[[\"open\",\"high\",\"low\",\"close\",\"volume\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCP (optional): symbol search + article extraction\n",
    "async def _make_mcp_client():\n",
    "    client = MCPClient()\n",
    "    for name, spec in MCP_SERVERS.items():\n",
    "        await client.add_server(name, command=spec[\"command\"], args=spec.get(\"args\", []))\n",
    "    await client.start()\n",
    "    return client\n",
    "\n",
    "async def _pick_tool(client: \"MCPClient\", candidates: List[str]) -> Optional[str]:\n",
    "    tools = await client.get_tools()\n",
    "    names = {t.get(\"name\"): t for t in tools}\n",
    "    for cand in candidates:\n",
    "        if cand in names:\n",
    "            return cand\n",
    "    lower_map = {k.lower(): k for k in names}\n",
    "    for cand in candidates:\n",
    "        if cand.lower() in lower_map:\n",
    "            return lower_map[cand.lower()]\n",
    "    return None\n",
    "\n",
    "def _extract_symbol_from_text(url: str, text: str) -> Optional[str]:\n",
    "    m = re.search(r\"/quote/([A-Z.\\-]{1,10})(?:[/?#]|$)\", url)\n",
    "    if m:\n",
    "        return m.group(1).upper()\n",
    "    m = re.search(r\"\\((?:NASDAQ|NYSE|AMEX|NYSEARCA|NYSEMKT)\\s*:\\s*([A-Z.\\-]{1,10})\\)\", text, re.I)\n",
    "    if m:\n",
    "        return m.group(1).upper()\n",
    "    m = re.search(r\"(?:Ticker\\s*(?:symbol)?\\s*[:\\-]\\s*)([A-Z.\\-]{1,10})\\b\", text, re.I)\n",
    "    if m:\n",
    "        return m.group(1).upper()\n",
    "    return None\n",
    "\n",
    "async def _mcp_symbol_search(company: str) -> Optional[str]:\n",
    "    client = await _make_mcp_client()\n",
    "    try:\n",
    "        search_tool = await _pick_tool(client, [\"search\",\"web_search\",\"google_search\",\"brave_search\"])\n",
    "        open_tool   = await _pick_tool(client, [\"open\",\"goto\",\"navigate\",\"open_url\"])\n",
    "        extract_tool= await _pick_tool(client, [\"extract\",\"read\",\"get_content\",\"get_text\"])\n",
    "        if not search_tool or not open_tool or not extract_tool:\n",
    "            return None\n",
    "\n",
    "        q = (f'{company} stock ticker '\n",
    "             f'site:finance.yahoo.com OR site:wikipedia.org OR site:reuters.com OR site:bloomberg.com')\n",
    "        res = await client.call(search_tool, {\"query\": q, \"num_results\": 8})\n",
    "        results = res.get(\"results\") or res.get(\"data\") or []\n",
    "\n",
    "        for r in results:\n",
    "            url = r.get(\"url\") or r.get(\"link\")\n",
    "            if not url:\n",
    "                continue\n",
    "            try:\n",
    "                await client.call(open_tool, {\"url\": url})\n",
    "                page = await client.call(extract_tool, {\"url\": url, \"max_chars\": 3000})\n",
    "                text = page.get(\"text\") or page.get(\"content\") or \"\"\n",
    "            except Exception:\n",
    "                text = r.get(\"snippet\",\"\") or \"\"\n",
    "            sym = _extract_symbol_from_text(url, text)\n",
    "            if sym:\n",
    "                return sym\n",
    "        return None\n",
    "    finally:\n",
    "        await client.stop()\n",
    "\n",
    "def resolve_company_to_symbol(company: str) -> Optional[str]:\n",
    "    sym = yahoo_symbol_search(company)\n",
    "    if sym:\n",
    "        return sym\n",
    "    if HAVE_MCP and MCP_SERVERS:\n",
    "        try:\n",
    "            return anyio.run(_mcp_symbol_search, company)\n",
    "        except Exception:\n",
    "            pass\n",
    "    return None\n",
    "\n",
    "def resolve_names_to_symbols(companies: List[str]) -> List[str]:\n",
    "    out: List[str] = []\n",
    "    for c in companies:\n",
    "        s = resolve_company_to_symbol(c)\n",
    "        if s and s not in out:\n",
    "            out.append(s)\n",
    "        # if nothing found, skip silently (we'll still have explicit tickers if any)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Research: MCP (optional) + RSS fallback\n",
    "def _rss_url_for_ticker(ticker: str) -> str:\n",
    "    from urllib.parse import quote\n",
    "    return f\"https://feeds.finance.yahoo.com/rss/2.0/headline?s={quote(ticker)}&region=US&lang=en-US\"\n",
    "\n",
    "def _collect_news_rss(ticker: str, days_window: int = 14, limit: int = 6) -> List[Dict[str, Any]]:\n",
    "    if not HAVE_RSS:\n",
    "        return []\n",
    "    feed = feedparser.parse(_rss_url_for_ticker(ticker))\n",
    "    items: List[Dict[str, Any]] = []\n",
    "    cutoff = datetime.now(timezone.utc) - timedelta(days=days_window)\n",
    "    seen = set()\n",
    "    for e in feed.entries:\n",
    "        title = _clean_text(getattr(e, \"title\", \"\"))\n",
    "        link  = getattr(e, \"link\", \"\")\n",
    "        if not title or not link:\n",
    "            continue\n",
    "        if getattr(e, \"published_parsed\", None):\n",
    "            pub = datetime(*e.published_parsed[:6], tzinfo=timezone.utc)\n",
    "        else:\n",
    "            pub = datetime.now(timezone.utc)\n",
    "        if pub < cutoff:\n",
    "            continue\n",
    "        dedup = hashlib.md5((title + link).encode()).hexdigest()\n",
    "        if dedup in seen:\n",
    "            continue\n",
    "        seen.add(dedup)\n",
    "\n",
    "        excerpt = \"\"\n",
    "        try:\n",
    "            r = requests.get(link, timeout=10, headers=USER_AGENT)\n",
    "            if r.status_code == 200 and 'text/html' in (r.headers.get(\"content-type\") or \"\"):\n",
    "                soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "                excerpt = _clean_text(soup.get_text(\" \", strip=True))[:700]\n",
    "        except Exception:\n",
    "            pass\n",
    "        if not excerpt:\n",
    "            excerpt = _clean_text(getattr(e, \"summary\", \"\"))[:700]\n",
    "\n",
    "        items.append({\"title\": title, \"url\": link, \"published\": pub.isoformat(), \"excerpt\": excerpt})\n",
    "        if len(items) >= limit:\n",
    "            break\n",
    "    return items\n",
    "\n",
    "async def _mcp_search_and_scrape(ticker: str, days_window: int = 14, max_items: int = 6) -> List[Dict[str, Any]]:\n",
    "    client = await _make_mcp_client()\n",
    "    try:\n",
    "        search_tool = await _pick_tool(client, [\"search\",\"web_search\",\"google_search\",\"brave_search\"])\n",
    "        open_tool   = await _pick_tool(client, [\"open\",\"goto\",\"navigate\",\"open_url\"])\n",
    "        extract_tool= await _pick_tool(client, [\"extract\",\"read\",\"get_content\",\"get_text\"])\n",
    "        if not search_tool or not open_tool or not extract_tool:\n",
    "            return _collect_news_rss(ticker, days_window, max_items)\n",
    "\n",
    "        q = (f'{ticker} stock news '\n",
    "             f'site:reuters.com OR site:bloomberg.com OR site:cnbc.com OR site:wsj.com OR site:investopedia.com')\n",
    "\n",
    "        res = await client.call(search_tool, {\"query\": q, \"num_results\": max_items * 2})\n",
    "        results = res.get(\"results\") or res.get(\"data\") or []\n",
    "        out, seen = [], set()\n",
    "        for r in results:\n",
    "            url = r.get(\"url\") or r.get(\"link\")\n",
    "            title = _clean_text(r.get(\"title\") or \"\")\n",
    "            if not url or not title:\n",
    "                continue\n",
    "            key = hashlib.md5((title + url).encode()).hexdigest()\n",
    "            if key in seen:\n",
    "                continue\n",
    "            seen.add(key)\n",
    "\n",
    "            excerpt = \"\"\n",
    "            try:\n",
    "                await client.call(open_tool, {\"url\": url})\n",
    "                page = await client.call(extract_tool, {\"url\": url, \"max_chars\": 2000})\n",
    "                text = page.get(\"text\") or page.get(\"content\") or \"\"\n",
    "                excerpt = _clean_text(text)[:700]\n",
    "            except Exception:\n",
    "                excerpt = _clean_text(r.get(\"snippet\") or \"\")[:700]\n",
    "\n",
    "            out.append({\"title\": title, \"url\": url, \"published\": r.get(\"date\") or r.get(\"published\") or \"\", \"excerpt\": excerpt})\n",
    "            if len(out) >= max_items:\n",
    "                break\n",
    "        return out\n",
    "    finally:\n",
    "        await client.stop()\n",
    "\n",
    "def _research_fallback_or_mcp(ticker: str, days_window: int = 14, max_items: int = 6) -> List[Dict[str, Any]]:\n",
    "    if HAVE_MCP and MCP_SERVERS:\n",
    "        try:\n",
    "            return anyio.run(_mcp_search_and_scrape, ticker, days_window, max_items)\n",
    "        except Exception:\n",
    "            pass\n",
    "    return _collect_news_rss(ticker, days_window, max_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agents\n",
    "def intent_agent(state: State) -> State:\n",
    "    \"\"\"LLM/heuristic parse + web symbol resolution (Yahoo JSON, then MCP if enabled).\"\"\"\n",
    "    parsed = _llm_extract(state.question)\n",
    "\n",
    "    companies = [c.strip() for c in (parsed.get(\"companies\") or []) if c.strip()]\n",
    "    explicit_tickers = list(dict.fromkeys(\n",
    "        (parsed.get(\"tickers\") or []) + re.findall(r\"\\b[A-Z]{1,5}\\b\", state.question)\n",
    "    ))\n",
    "\n",
    "    resolved = resolve_names_to_symbols(companies)\n",
    "    tickers = explicit_tickers + [t for t in resolved if t not in explicit_tickers]\n",
    "\n",
    "    start = _parse_date_or_none(parsed.get(\"date_from\"))\n",
    "    end   = _parse_date_or_none(parsed.get(\"date_to\"))\n",
    "\n",
    "    state.companies = companies\n",
    "    state.tickers = tickers or state.tickers or [\"AAPL\"]\n",
    "    state.start, state.end = _default_dates(start or state.start, end or state.end)\n",
    "    state.interval = _pick_interval(state.start, state.end)\n",
    "    return state\n",
    "\n",
    "def data_agent(state: State) -> State:\n",
    "    for sym in state.tickers:\n",
    "        try:\n",
    "            js = _get_chart_json(sym, state.start, state.end, state.interval)\n",
    "            df = _chart_to_dataframe(js)\n",
    "            state.prices[sym] = df\n",
    "            meta = js[\"chart\"][\"result\"][0].get(\"meta\", {})\n",
    "            state.quotes[sym] = {\n",
    "                \"regularMarketPrice\": meta.get(\"regularMarketPrice\"),\n",
    "                \"currency\": meta.get(\"currency\")\n",
    "            }\n",
    "        except Exception:\n",
    "            df = _yfinance_fallback(sym, state.start, state.end, state.interval)\n",
    "            state.prices[sym] = df\n",
    "            state.quotes[sym] = {\n",
    "                \"regularMarketPrice\": float(df[\"close\"].iloc[-1]),\n",
    "                \"currency\": \"USD\"\n",
    "            }\n",
    "    return state\n",
    "\n",
    "def research_agent(state: State) -> State:\n",
    "    window_days = min(30, max(7, (state.end - state.start).days if state.end and state.start else 14))\n",
    "    research: Dict[str, List[Dict[str, Any]]] = {}\n",
    "    for sym in state.tickers:\n",
    "        research[sym] = _research_fallback_or_mcp(sym, days_window=window_days, max_items=6)\n",
    "    state.research = research\n",
    "    return state\n",
    "\n",
    "def analysis_agent(state: State) -> State:\n",
    "    out: Dict[str, Any] = {}\n",
    "    for sym, df in state.prices.items():\n",
    "        ret = df[\"close\"].pct_change().dropna()\n",
    "        cum = (1 + ret).prod() - 1\n",
    "        vol = ret.std() * math.sqrt(252 if state.interval in (\"1d\",\"1h\",\"15m\") else 52)\n",
    "        max_dd = ((df[\"close\"]/df[\"close\"].cummax()) - 1).min()\n",
    "        ma20 = df[\"close\"].rolling(20).mean().iloc[-1]\n",
    "        ma50 = df[\"close\"].rolling(50).mean().iloc[-1] if len(df) >= 50 else None\n",
    "        out[sym] = {\n",
    "            \"period_return\": float(cum),\n",
    "            \"vol_annualized\": float(vol),\n",
    "            \"max_drawdown\": float(max_dd),\n",
    "            \"ma20\": float(ma20) if ma20 else None,\n",
    "            \"ma50\": float(ma50) if ma50 else None\n",
    "        }\n",
    "    state.analysis = out\n",
    "    return state\n",
    "\n",
    "def viz_agent(state: State) -> State:\n",
    "    for sym, df in state.prices.items():\n",
    "        if df.empty:\n",
    "            continue\n",
    "        fig, ax = plt.subplots()\n",
    "        df[\"close\"].plot(ax=ax, label=\"Close\", linewidth=1.2)\n",
    "        try:\n",
    "            df[\"close\"].rolling(20).mean().plot(ax=ax, label=\"MA20\", linestyle=\"--\")\n",
    "            if len(df) >= 50:\n",
    "                df[\"close\"].rolling(50).mean().plot(ax=ax, label=\"MA50\", linestyle=\":\")\n",
    "        except Exception:\n",
    "            pass\n",
    "        ax.set_title(f\"{sym} Price — {state.start.date()} to {state.end.date()}\")\n",
    "        ax.set_xlabel(\"Date\")\n",
    "        ax.set_ylabel(\"Price\")\n",
    "        ax.legend(loc=\"best\", fontsize=\"small\", frameon=True)\n",
    "        path = f\"{sym}_chart.png\"\n",
    "        plt.savefig(path, bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "        state.charts[sym] = path\n",
    "    return state\n",
    "\n",
    "def report_agent(state: State) -> State:\n",
    "    lines: List[str] = []\n",
    "    if state.companies:\n",
    "        lines.append(f\"**Resolved companies → tickers:** {', '.join(state.companies)} → {', '.join(state.tickers)}\\n\")\n",
    "\n",
    "    for sym in state.tickers:\n",
    "        q = state.quotes.get(sym, {})\n",
    "        a = state.analysis.get(sym, {})\n",
    "        price = q.get(\"regularMarketPrice\")\n",
    "        pr = a.get(\"period_return\"); vol = a.get(\"vol_annualized\"); dd = a.get(\"max_drawdown\")\n",
    "        ma20 = a.get(\"ma20\"); ma50 = a.get(\"ma50\")\n",
    "\n",
    "        lines.append(\n",
    "            f\"**{sym}** — Last price ~ {price} {q.get('currency','')}. \"\n",
    "            f\"Window {state.start.date()}→{state.end.date()}: \"\n",
    "            f\"total return ≈ {pr:.1%}, annualized volatility ≈ {vol:.1%}, \"\n",
    "            f\"max drawdown ≈ {dd:.1%}. \"\n",
    "            f\"Trend check: 20-day MA {('>=' if ma50 and ma20>=ma50 else '<' if ma50 else '≈')} 50-day MA.\"\n",
    "        )\n",
    "\n",
    "        news_items = state.research.get(sym, [])\n",
    "        if news_items:\n",
    "            lines.append(\"**Research highlights (recent):**\")\n",
    "            for it in news_items[:5]:\n",
    "                excerpt = it.get(\"excerpt\",\"\")[:160]\n",
    "                lines.append(f\"- {it.get('title','(no title)')} — {excerpt} ({it.get('url','')})\")\n",
    "        lines.append(\"\")\n",
    "\n",
    "    disclaimer = (\n",
    "        \"_Note: Educational analysis, not investment advice. \"\n",
    "        \"Yahoo endpoints are unofficial and may change. \"\n",
    "        \"External links are for reference—verify with primary sources._\"\n",
    "    )\n",
    "    state.report = \"\\n\".join(lines).strip() + \"\\n\\n\" + disclaimer\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "def build_app():\n",
    "    g = StateGraph(State)   # ensure we get a State object back\n",
    "    g.add_node(\"intent\", intent_agent)\n",
    "    g.add_node(\"data\", data_agent)\n",
    "    g.add_node(\"research\", research_agent)\n",
    "    g.add_node(\"analysis\", analysis_agent)\n",
    "    g.add_node(\"viz\", viz_agent)\n",
    "    g.add_node(\"report\", report_agent)\n",
    "\n",
    "    g.add_edge(START, \"intent\")\n",
    "    g.add_edge(\"intent\", \"data\")\n",
    "    g.add_edge(\"data\", \"research\")\n",
    "    g.add_edge(\"research\", \"analysis\")\n",
    "    g.add_edge(\"analysis\", \"viz\")\n",
    "    g.add_edge(\"viz\", \"report\")\n",
    "    g.add_edge(\"report\", END)\n",
    "    return g.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = build_app()\n",
    "\n",
    "# Example 1\n",
    "s1 = app.invoke(State(question=\"Analyze Apple from Jan 1, 2023 to Aug 31, 2025\"))\n",
    "_print_result(s1)\n",
    "\n",
    "# Example 2\n",
    "# s2 = app.invoke(State(question=\"Compare Tesla and NVIDIA\"))\n",
    "# _print_result(s2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (finance-env)",
   "language": "python",
   "name": "finance-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
